---
title: "6. Model selection"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(biPOD)
```

The package gives the opportunity to perform model selection over a list of biPOD object that have been fitted. The two models must have some of their characteristics shared:

- same sampling method (variational vs MCMC)
- same type of prior
- same parameters for the prior

Moreover, the package gives the opportunity to perform model selection using either the Bayes Factor (BF) ratio or the Pareto smoothed importance-sampling leave-one-out cross-validation (LOO).

This can be useful in different cases which will presented in the following paragraphs.

# Exponential or Logistic?

One could ask if a given dataset is better explained by a logistic or exponential growth.
Hence, let's first simulate a logistic growth with the following parameters:

```{r}
n0 = 1000
lambda = 1
mu = .5
K = 3000
T = 2
steps = 10
delta_t = T / steps

# Simulate logistic
d <- biPOD::sim_stochastic_logistic(n0, lambda, mu, K, steps, delta_t)
```

We can then fit two different models, one assuming an exponential growth and one assuming a logistic growth.

```{r}
# Fit exponential
x.exp <- biPOD::init(d, "")
x.exp <- biPOD::fit(x.exp, growth_type = "exponential")

# Fit logistic
x.log <- biPOD::init(d, "")
x.log <- biPOD::fit(x.log, growth_type = "logistic")
```

And then one can compute the Bayes factor between the models using the `bf_selection` function.
The function returns the pairwise Bayes factors between the models. The highest the value of the BF between two models, the better the first model is with respect to the other. 

```{r}
bf <- biPOD::bf_selection(list(x.exp, x.log))
bf
```

It appears clear that the preferred model is the one which assumes an exponential growth. This is due to the fact that the simulated data set is still far from reaching the plateau of the logistic growth. Also from a visual inspection one can see that the exponential growth is better.

```{r}
plots <- lapply(list(x.exp, x.log), function(x) {
  return(biPOD::plot_fit(x, add_title = T))
})
ggpubr::ggarrange(plotlist = plots, ncol=2)
```

On the other hand, if we increase the length of the process, letting the logistic pattern show up, the situation changes.

```{r}
T = 5
steps = 10
delta_t = T / steps

# Simulate logistic
d <- biPOD::sim_stochastic_logistic(n0, lambda, mu, K, steps, delta_t)
```

Let's fit again:

```{r}
# Fit exponential
x.exp <- biPOD::init(d, "")
x.exp <- biPOD::fit(x.exp, growth_type = "exponential")

# Fit logistic
x.log <- biPOD::init(d, "")
x.log <- biPOD::fit(x.log, growth_type = "logistic")
```

Now the Bayes Factor should be quite different

```{r}
bf <- biPOD::bf_selection(list(x.exp, x.log))
bf
```

And let's inspect visually the results.

```{r}
plots <- lapply(list(x.exp, x.log), function(x) {
  return(biPOD::plot_fit(x, add_title = T))
})
ggpubr::ggarrange(plotlist = plots, ncol=2)
```

# Which carrying capacity?

Another possibility is to use only the logistic fit with different priors for the carrying capacity K and then select the one with the highest Bayes Factor. More interestingly, this process is general and can be used also to fit an exponential growth (in this case K >> N_i where N_i are the observations).

Let's simulate an exponential growth (i.e. the carrying capacity K is infinite)

```{r}
n0 = 1000
lambda = 1
mu = .5
T = 2
steps = 10
delta_t = T / steps

# Simulate exponential
d <- biPOD::sim_stochastic_exponential(n0, lambda, mu, steps, delta_t)
```

And 

